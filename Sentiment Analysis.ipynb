{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens:\n",
      "['breath-taking', 'ambitious', 'movie', 'test', 'text', 'abc_dcd', 'abc-dcd']\n"
     ]
    }
   ],
   "source": [
    "import nltk, re, string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# library for normalization\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# numpy is the package for matrix caculation\n",
    "import numpy as np  \n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "def tokenize(text):\n",
    "    \n",
    "    \n",
    "    \n",
    "    # write your code here\n",
    "    kens=[] \n",
    "    kens=[token.strip() \\\n",
    "            for token in nltk.word_tokenize(text.lower()) \\\n",
    "            if token.strip() not in stop_words and\\\n",
    "               token.strip() not in string.punctuation]\n",
    "    tokens= [ k \\\n",
    "              for k in kens \\\n",
    "              if k in re.findall(r'^[^-_].*[^-_]$',k) and\\\n",
    "                 k  in re.findall(r'\\D+',k)  ]\n",
    "    # you can add bigrams, collocations, or lemmatization here\n",
    "    \n",
    "    # create token count dictionary\n",
    "    \n",
    "    \n",
    "    # or you can create dictionary by yourself\n",
    "    #token_count={token:tokens.count(token) for token in set(tokens)}\n",
    " \n",
    "    return tokens\n",
    "\n",
    "if __name__ == \"__main__\":  \n",
    "   # add text here\n",
    "    \n",
    "    text=\"this is a breath-taking ambitious movie; test text: abc_dcd abc_ dvr89w, abc-dcd -abc\"\n",
    "\n",
    "    \n",
    "    print(\"tokens:\")\n",
    "    print(tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re, string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# library for normalization\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# numpy is the package for matrix caculation\n",
    "import numpy as np  \n",
    "\n",
    "def sentiment_analysis(text, positive_words, negative_words):\n",
    "    \n",
    "    sentiment=None\n",
    "    \n",
    "    # write your code here\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    negations=['not', 'too', 'n\\'t', 'no', 'cannot', 'neither','nor']\n",
    "\n",
    "\n",
    "    #print(tokens)\n",
    "    negative_tokens=[]\n",
    "    positive_tokens=[]\n",
    "    for idx, token in enumerate(tokens):\n",
    "        if token in positive_words:\n",
    "            if idx>=0:\n",
    "                if tokens[idx-1] not in negations:\n",
    "                    positive_tokens.append(token)\n",
    "                else:\n",
    "                    negative_tokens.append(token)\n",
    "        if token in negative_words:\n",
    "            if idx>=0:\n",
    "                if tokens[idx-1] not in negations:\n",
    "                    negative_tokens.append(token)\n",
    "                else:\n",
    "                    positive_tokens.append(token)\n",
    "        \n",
    "    if len( positive_tokens) <= len( negative_tokens):\n",
    "        sentiment=1\n",
    "    else:\n",
    "        sentiment=2\n",
    "    #len( positive_tokens)\n",
    "    #print(negative_tokens)\n",
    "    \n",
    "    \n",
    "    return sentiment\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sentiment\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":  \n",
    "    \n",
    "    text=\"this is a breath-taking ambitious movie; test text: abc_dcd abc_ dvr89w, abc-dcd -abc\"\n",
    "\n",
    "   \n",
    "    \n",
    "    with open(\"positive-words.txt\",'r') as f:\n",
    "        positive_words=[line.strip() for line in f]\n",
    "        \n",
    "    with open(\"negative-words.txt\",'r') as f:\n",
    "        negative_words=[line.strip() for line in f]\n",
    "        \n",
    "    print(\"\\nsentiment\")\n",
    "    sentiment=sentiment_analysis(text, positive_words, negative_words)\n",
    "    print(sentiment)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
